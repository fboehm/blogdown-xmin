<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home on Frederick Boehm&#39;s Professional Website</title>
    <link>/</link>
    <description>Recent content in Home on Frederick Boehm&#39;s Professional Website</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 07 Feb 2018 13:04:42 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Travis-CI and R packages: What to do when your Travis-CI build takes too long</title>
      <link>/post/2018/02/07/travis-ci-and-r-packages-what-to-do-when-your-travis-ci-build-takes-too-long/</link>
      <pubDate>Wed, 07 Feb 2018 13:04:42 +0000</pubDate>
      
      <guid>/post/2018/02/07/travis-ci-and-r-packages-what-to-do-when-your-travis-ci-build-takes-too-long/</guid>
      <description>I use Travis-CI with my R packages on Github. By doing so, unit tests for my package are run each time I add a commit to my Github repository.
I recently encountered for the first time an error that results from my R package vignette taking too long to build. I was aware that the package vignette would take a long time - about 20 to 30 minutes - to build, but I hadn’t realized that Travis would return an error because of this.</description>
    </item>
    
    <item>
      <title>`git add` &amp; the `-u` flag</title>
      <link>/post/2017/12/14/git-add-the-u-flag/</link>
      <pubDate>Thu, 14 Dec 2017 02:20:40 +0000</pubDate>
      
      <guid>/post/2017/12/14/git-add-the-u-flag/</guid>
      <description>Overview I am still learning git, despite the fact that I’ve been trying to use it for 3 or more years. Today I needed to stage deleted files (i.e., files that I previously added to the repository). I tried
git add . but I then saw, after typing
git status that the deleted files remained unstaged.
A quick google search turned up this discussion. I then changed directories to the directory that is the root, or source - I’m not sure of the proper term - for my repository, and typed</description>
    </item>
    
    <item>
      <title>High-throughput computing &amp; working with condor</title>
      <link>/draft/high-throughput-computing-working-with-condor/</link>
      <pubDate>Thu, 14 Dec 2017 02:02:55 +0000</pubDate>
      
      <guid>/draft/high-throughput-computing-working-with-condor/</guid>
      <description>Overview I’m learning to use a high-throughput computing facility - the Center for High-Throughput Computing at the University of Wisconsin-Madison. Below, I detail my experience in preparing my code for using the CHTC’s computers. What follows may be boring for the non-specialist (and, possibly, for the specialist, too).
 The problem I need to fit tens of thousands - millions, even - of linear mixed effects models for my research in systems genetics.</description>
    </item>
    
    <item>
      <title>Generalized variance inflation factors</title>
      <link>/draft/generalized-variance-inflation-factors/</link>
      <pubDate>Thu, 14 Dec 2017 01:38:12 +0000</pubDate>
      
      <guid>/draft/generalized-variance-inflation-factors/</guid>
      <description>Overview of the statistical model I am working with a linear mixed effects model,
\[vec(Y) = Xvec(B) + vec(G) + vec(E)\]
where \(Y\) is a n by 2 matrix of trait values with one row per subject and one column per trait, \(X\) is a 2n by 2f matrix containing genotypic data in two n by f blocks, both of which are one the diagonal (i.e., \(X\) is a block-diagonal matrix with two diagonal blocks), \(B\) is a f by 2 matrix of allele effect sizes, \(G\) is a n by 2 matrix of genotypic random effects, and \(E\) is a n by 2 matrix of random errors.</description>
    </item>
    
    <item>
      <title>Thoughts on Knott &amp; Haley (2000)</title>
      <link>/draft/thoughts-on-knott-haley-2000/</link>
      <pubDate>Thu, 14 Dec 2017 01:37:48 +0000</pubDate>
      
      <guid>/draft/thoughts-on-knott-haley-2000/</guid>
      <description>Overview I’ve been reading Knott and Haley (2000), an article that discusses methods for multivariate QTL mapping. I’m trying to pay special attention to their methods for testing the competing hypotheses of 1. close linkage and 2. pleiotropy for a pair of traits that map to a single genomic region.
 References Knott, Sara A, and Chris S Haley. 2000. “Multitrait Least Squares for Quantitative Trait Loci Detection.” Genetics 156 (2).</description>
    </item>
    
    <item>
      <title>R code profiling saves the day!</title>
      <link>/post/2017/10/16/r-code-profiling-saves-the-day/</link>
      <pubDate>Mon, 16 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/10/16/r-code-profiling-saves-the-day/</guid>
      <description>Overview I recently needed to write R code to fit a linear model using generalized least squares (GLS). My initial attempt at writing functions to do this, while technically correct, seemed to be slow. For example, fitting about 100 such models took nearly 30 minutes on my MacBook Pro computer.
My graduate school advisors suggested that I re-examine my code to see if I could find inefficiencies. For instance, if one were fitting multiple models with ordinary least squares (OLS), and the models all have the same design matrix, but distinct response vectors, then one could save computations by calculating only once the matrix \[(X^TX)^{-1}X^T\] and merely plugging in the response vector many times, using matrix multiplication, to get the OLS estimators for each model:</description>
    </item>
    
    <item>
      <title>Using `dplyr` functions in my R package</title>
      <link>/post/2017/09/11/using-dplyr-functions-in-my-r-package/</link>
      <pubDate>Mon, 11 Sep 2017 14:51:29 +0000</pubDate>
      
      <guid>/post/2017/09/11/using-dplyr-functions-in-my-r-package/</guid>
      <description>Background I wrote the following function for use in my pleiotropy R package.
calc_lod &amp;lt;- function(data, n_mouse){ # define log10detrss0 log10detrss0 &amp;lt;- dplyr::filter(data, marker1 == marker2) pre1 &amp;lt;- dplyr::group_by(data, marker1) profile1 &amp;lt;- dplyr::summarise(pre1, profile = min(log10detrss)) pre2 &amp;lt;- dplyr::group_by(data, marker2) profile2 &amp;lt;- dplyr::summarise(pre2, profile = min(log10detrss)) return(tibble::tibble(lod1 = - n_mouse * (profile1$profile - min(log10detrss0$log10detrss)) / 2, lod2 = - n_mouse * (profile2$profile - min(log10detrss0$log10detrss))/ 2, joint = - n_mouse * (log10detrss0$log10detrss - min(log10detrss0$log10detrss)) / 2)) } I then wanted to include this function in my R package pleiotropy.</description>
    </item>
    
    <item>
      <title>Joan Didion’s &#34;On self-respect&#34;</title>
      <link>/post/2017/09/10/joan-didion-s-on-self-respect/</link>
      <pubDate>Sun, 10 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/09/10/joan-didion-s-on-self-respect/</guid>
      <description>Yesterday I read for the first time Joan Didion’s essay “On self-respect” in her 1968 collection of essays “Slouching towards Bethlehem”. “On self-respect” originally appeared in Vogue in 1961. Here is the text of the essay, as it appeared in 1961.

Among the more powerful lines from the essay are the following:
“Nonetheless, character — the willingness to accept responsibility for one’s own life — is the source from which self-respect springs.</description>
    </item>
    
    <item>
      <title>Understanding REML for estimating variance components</title>
      <link>/post/2017/09/02/understanding-reml-for-estimating-variance-components/</link>
      <pubDate>Sat, 02 Sep 2017 12:38:19 +0000</pubDate>
      
      <guid>/post/2017/09/02/understanding-reml-for-estimating-variance-components/</guid>
      <description>Overview I used much of the summer of 2017 to study linear mixed effects models. I’m writing this blog post to document my experience. Perhaps readers will find it useful in designing their study plans for mixed models.
I found particularly useful Sections 8.4 and 8.5 of Wakefield (2013). The author describes in detail a general framework for linear mixed models before venturing into likelihood-based inference for these models. Particularly appealing to me, and differing from works of many others, is the emphasis of Wakefield (2013) on being explicit about conditioning.</description>
    </item>
    
    <item>
      <title>Mathematical Writing by Donald Knuth, Tracy Larrabee, and Paul Roberts</title>
      <link>/post/2017/08/16/mathematical-writing-by-donald-knuth-tracy-larrabee-and-paul-roberts/</link>
      <pubDate>Wed, 16 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/08/16/mathematical-writing-by-donald-knuth-tracy-larrabee-and-paul-roberts/</guid>
      <description>I recently applied for a peer review training program that the Genetics Society of America organizes. An advisor kindly agreed to write a recommendation for my application. In discussing the program application with him, he told me that most of what he knows about refereeing he learned from Don Knuth’s book, Mathematical Writing. I decided to find a copy of the book. The publisher, MAA, says that the book is out of print.</description>
    </item>
    
    <item>
      <title>My presentation materials on Figshare</title>
      <link>/post/2017/07/14/my-presentation-materials-on-figshare/</link>
      <pubDate>Fri, 14 Jul 2017 10:52:36 +0000</pubDate>
      
      <guid>/post/2017/07/14/my-presentation-materials-on-figshare/</guid>
      <description>I’m trying to remember to post my presentation materials on figshare.com. You can find them by clicking on the figshare icon on my home page or by clicking here. Included is the poster that I presented yesterday at PolMeth XXXIV.</description>
    </item>
    
    <item>
      <title>Testing my R package</title>
      <link>/post/2017/07/14/testing-my-r-package/</link>
      <pubDate>Fri, 14 Jul 2017 10:52:36 +0000</pubDate>
      
      <guid>/post/2017/07/14/testing-my-r-package/</guid>
      <description>I am assembling a package that implements an EM algorithm. I want to think about how I know whether the code works. Certainly, we know that an EM algorithm requires that the likelihood be non-decreasing over consecutive iterations.
In looking at resources on testing, I found particularly helpful Karl Broman’s slides on testing R code. Hadley Wickham’s book Advanced R has a useful chapter on testing.</description>
    </item>
    
    <item>
      <title>Translating GEMMA’s Newton-Raphson Algorithm from C&#43;&#43; to R</title>
      <link>/post/2017/07/04/translating-gemma-s-newton-raphson-algorithm-from-c-to-r/</link>
      <pubDate>Tue, 04 Jul 2017 10:13:52 +0000</pubDate>
      
      <guid>/post/2017/07/04/translating-gemma-s-newton-raphson-algorithm-from-c-to-r/</guid>
      <description>Overview We want to translate GEMMA’s C++ code in the function MphNR (in the file mvlmm.cpp) into R code as a way to better understand the calculations and the algorithm.
MphNR C++ Code MphNR is defined in these lines in the GEMMA Github repository.
 R code for MphNR #double MphNR (const char func_name, const size_t max_iter, const double max_prec, const gsl_vector *eval, const gsl_matrix *X, const gsl_matrix *Y, gsl_matrix *Hi_all, gsl_matrix *xHi_all, gsl_matrix *Hiy_all, gsl_matrix *V_g, gsl_matrix *V_e, gsl_matrix *Hessian_inv, double &amp;amp;crt_a, double &amp;amp;crt_b, double &amp;amp;crt_c) #{ MphNR &amp;lt;- function(func_name = &amp;quot;R&amp;quot;, max_iter, max_prec, eval, X, Y, Hi_all, xHi_all, Hiy_all, V_g, V_e){ n_size &amp;lt;- length(eval) c_size &amp;lt;- nrow(X) d_size &amp;lt;- nrow(Y) dc_size &amp;lt;- d_size * c_size v_size &amp;lt;- d_size * (d_size + 1) / 2 XXt &amp;lt;- X %*% t(X) log(det(XXt)) -&amp;gt; lndetXXt if (func_name == &amp;quot;R&amp;quot;){ logl_const &amp;lt;- - 0.</description>
    </item>
    
    <item>
      <title>Deciphering GEMMA’s C&#43;&#43; Code</title>
      <link>/post/2017/07/04/deciphering-gemma-s-c-code/</link>
      <pubDate>Tue, 04 Jul 2017 10:13:51 +0000</pubDate>
      
      <guid>/post/2017/07/04/deciphering-gemma-s-c-code/</guid>
      <description>library(knitr) opts_chunk$set(eval = FALSE) My goal is to translate the C++ code in GEMMA/src/mvlmm.cpp to mathematical notation and, ultimately, to R code. Zhou’s C++ code uses the gsl C++ library.
CalcXHiY C++ code Let’s examine the function CalcXHiY which runs from line 357-384 of mvlmm.cpp. I reproduce them here:
void CalcXHiY(const gsl_vector *eval, const gsl_vector *D_l, const gsl_matrix *X, const gsl_matrix *UltVehiY, gsl_vector *xHiy) { size_t n_size=eval-&amp;gt;size, c_size=X-&amp;gt;size1, d_size=D_l-&amp;gt;size; gsl_vector_set_zero (xHiy); double x, delta, dl, y, d; for (size_t i=0; i&amp;lt;d_size; i++) { dl=gsl_vector_get(D_l, i); for (size_t j=0; j&amp;lt;c_size; j++) { d=0.</description>
    </item>
    
    <item>
      <title>John Roberts&#39;s Commencement Address</title>
      <link>/post/2017/07/03/john-roberts-s-commencement-address/</link>
      <pubDate>Mon, 03 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/07/03/john-roberts-s-commencement-address/</guid>
      <description>This afternoon, while listening to “All Things Considered” on Wisconsin Public Radio, I heard an excerpt from John Roberts’s recent commencement address. Here is the story from “All Things Considered”. Here is the YouTube video.

Roberts spoke at his son’s 9th grade graduation from The Cardigan Mountain School, a boarding school for boys in grades 6 to 9, on June 3, 2017.</description>
    </item>
    
    <item>
      <title>A ‘page’ type for blogdown &amp; hugo lithium theme</title>
      <link>/post/2017/05/23/a-page-type-for-blogdown-hugo-lithium-theme/</link>
      <pubDate>Tue, 23 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/05/23/a-page-type-for-blogdown-hugo-lithium-theme/</guid>
      <description>I didn’t like the fact that my ‘About’ and ‘Research’ pages included a Disqus section, as I don’t need comments on these materials. I decided to find a way to create pages - which are not blog posts - that don’t have the Disqus section. I’m using, as of right now, Yihui Xie’s hugo lithium theme, with a few small modifications that I’ve documented in my first blog post.
The Hugo documentation on types is quite good.</description>
    </item>
    
    <item>
      <title>GEMMA&#39;s EM algorithm implemented in R</title>
      <link>/post/2017/05/16/gemma-em-in-r/</link>
      <pubDate>Tue, 16 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/05/16/gemma-em-in-r/</guid>
      <description>I need to estimate variance components for a linear mixed effects model. Specifically, I need to consider the model, from Zhou and Stephens (2014):
\[Y = BX + G + E\] where \(Y\) is a \(2\) by \(n\) matrix of (possibly correlated) phenotypes (for \(n\) subjects), \(B\) is a \(2\) by \(c\) matrix of allelic effect sizes (where \(c\) denotes the number of alleles per locus), \(X\) is a \(c\) by \(n\) matrix containing genotypes (or genotype probabilities), \(G\) is a \(2\) by \(n\) matrix of random effects and \(E\) is a \(2\) by \(n\) matrix of random errors, which are assumed to be independent of \(G\).</description>
    </item>
    
    <item>
      <title>Getting started with blogdown</title>
      <link>/post/2017/05/07/getting-started-with-blogdown/</link>
      <pubDate>Sun, 07 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/05/07/getting-started-with-blogdown/</guid>
      <description>While browsing the internet, I stumbled upon Rstudio’s new package blogdown. I read posts from Karl Broman and found the the book that the package authors - Yihui Xie and Amber Thomas - freely share.
One tricky part of setting up the website involved the DNS settings. I bought the site fboehm.us through google domains. While the blogdown book provides instructions for DNS settings for other domain name providers, at the time I set up my site, they hadn’t written instructions for use with google domains.</description>
    </item>
    
    <item>
      <title>About Me</title>
      <link>/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/about/</guid>
      <description>I am a systems genetics and data science researcher and teacher who currently lives in Madison, Wisconsin, USA. I’m nearing completion of a Ph.D. in statistics from the University of Wisconsin-Madison.
You can find an updated CV here</description>
    </item>
    
  </channel>
</rss>